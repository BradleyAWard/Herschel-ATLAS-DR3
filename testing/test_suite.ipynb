{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### TESTING\n",
    "\n",
    " Functions that have been tested:\n",
    "\n",
    "- stellar_locus(x, offset)\n",
    "- classification(data, counterpart_id: str, j: str, k: str, g: str, i: str, pstar: str)\n",
    "- blanks(data, r_limit, groupid: str, distance: str)\n",
    "- TODO N(data, background, Ndata, Nback, r, band: str, bins=40, mag_min=9, mag_max=22)\n",
    "- TODO q_div_n(n_real, n_normalized, q0, bincentres, window_size, mag_min=9, mag_max=22, n=100)\n",
    "- TODO likelihood(data, counterpart_id: str, f250: str, e250: str, SG: str, distance: str, band: str, k, fwhm, qn_gal: tuple, qn_stars: tuple)\n",
    "- reliability(data, counterpart_id: str, groupid: str, likelihood: str, q0)\n",
    "- N_false(data, reliability: str, r_thresh)\n",
    "- completeness(data, reliability: str, f250: str, e250: str, q0, r_thresh, snr_thresh=4)\n",
    "- cleanness(data, reliability: str, r_thresh)\n",
    "- TODO multiplicity_reliability(sources, groupid: str, groupsize: str, distance: str, reliability: str, r_thresh=0.8, max_counterparts=10)\n",
    "- TODO euclidean_counts(data, flux: str, s_range: tuple, N, area)\n",
    "- TODO dn_dz_domega(data, min_z, max_z, n, area)\n",
    "- TODO lensing_probabilities(data, redshift_source: str, redshift_lens: str, redshift_error_source: str, redshift_error_lens: str)\n",
    "- TODO optimal_lens_probability(data, reliability: str, lensing_probability: str, z_source: str, false_id_percent, reliability_thresh=0.8, minimum_z_source=2.5, n=100)\n",
    "- TODO cumulative_counts(data, flux: str, s_range: tuple, N, area)\n",
    "- TODO lensing_fraction(data, lensed_candidates, f500: str, s_range: tuple, N, area)\n",
    "- TODO genuine_multiples(data, distance: str, groupid: str, redshift: str, redshift_errors: str, maximum_radius=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# =========================================================================================================\n",
    "# Dependencies\n",
    "# =========================================================================================================\n",
    "\n",
    "import pytest\n",
    "import ipytest\n",
    "import utils\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import read_csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# =========================================================================================================\n",
    "# Import test data\n",
    "# =========================================================================================================\n",
    "\n",
    "@pytest.fixture(scope='module')\n",
    "def test_data():\n",
    "    \"\"\" RETURNS OUR TEST DATA \"\"\"\n",
    "    ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))\n",
    "    file_path = ROOT + '/testing/test_data.csv'\n",
    "    data = read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "@pytest.fixture(scope='module')\n",
    "def test_back():\n",
    "    \"\"\" RETURNS OUR TEST DATA \"\"\"\n",
    "    ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))\n",
    "    file_path = ROOT + '/testing/test_data.csv'\n",
    "    back = read_csv(file_path)\n",
    "    return back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock Herschel Data\n",
      "    counterpart_id  J     K    g     i  pstar  SG_flag  group_id  distance  \\\n",
      "0                1  0   0.0  0.0   0.0   0.98        0       1.0         4   \n",
      "1                2  4   2.0  4.0   2.0   0.50        1       1.0         8   \n",
      "2                3  4   3.5  4.0   2.0   0.50        2       1.0        12   \n",
      "3                4  4   3.0  0.0  10.0   0.50        3       2.0         5   \n",
      "4                5  4   3.9  0.0  10.0   0.50        4       2.0         3   \n",
      "5                6  0  10.0  0.0  10.0   0.75        5       3.0         2   \n",
      "6                7  0  10.0  0.0  10.0   0.50        6       3.0        10   \n",
      "7                8  0   0.0  NaN   NaN   0.98        0       3.0         6   \n",
      "8                9  4   2.0  4.0   2.0   0.50        1       4.0        13   \n",
      "9               10  4   3.5  4.0   2.0   0.50        2       4.0        14   \n",
      "10              11  4   3.0  NaN   NaN   0.50        3       NaN        10   \n",
      "11              12  4   3.9  NaN   NaN   0.50        4       NaN         1   \n",
      "12              13  0  10.0  NaN   NaN   0.75        5       NaN         0   \n",
      "13              14  0  10.0  NaN   NaN   0.50        6       NaN         0   \n",
      "\n",
      "    group_size  ...   f500  e500  SG  likelihood  reliability  z_source  \\\n",
      "0          3.0  ...  0.020   NaN NaN           1         0.05       NaN   \n",
      "1          3.0  ...  0.024   NaN NaN           5         0.15       NaN   \n",
      "2          3.0  ...  0.028   NaN NaN          10         0.80       NaN   \n",
      "3          2.0  ...  0.030   NaN NaN           2         0.40       NaN   \n",
      "4          2.0  ...  0.032   NaN NaN           4         0.60       NaN   \n",
      "5          3.0  ...  0.035   NaN NaN           2         0.10       NaN   \n",
      "6          3.0  ...  0.040   NaN NaN           4         0.20       NaN   \n",
      "7          3.0  ...  0.045   NaN NaN           6         0.70       NaN   \n",
      "8          2.0  ...  0.050   NaN NaN           4         0.40       NaN   \n",
      "9          2.0  ...  0.060   NaN NaN           8         0.60       NaN   \n",
      "10         NaN  ...  0.080   NaN NaN           1         0.20       NaN   \n",
      "11         NaN  ...  0.100   NaN NaN           5         0.50       NaN   \n",
      "12         NaN  ...  0.150   NaN NaN           0         0.00       NaN   \n",
      "13         NaN  ...  0.200   NaN NaN           0         0.00       NaN   \n",
      "\n",
      "    z_err_source  z_lens  z_err_lens  lens_probability  \n",
      "0            NaN     NaN         NaN               NaN  \n",
      "1            NaN     NaN         NaN               NaN  \n",
      "2            NaN     NaN         NaN               NaN  \n",
      "3            NaN     NaN         NaN               NaN  \n",
      "4            NaN     NaN         NaN               NaN  \n",
      "5            NaN     NaN         NaN               NaN  \n",
      "6            NaN     NaN         NaN               NaN  \n",
      "7            NaN     NaN         NaN               NaN  \n",
      "8            NaN     NaN         NaN               NaN  \n",
      "9            NaN     NaN         NaN               NaN  \n",
      "10           NaN     NaN         NaN               NaN  \n",
      "11           NaN     NaN         NaN               NaN  \n",
      "12           NaN     NaN         NaN               NaN  \n",
      "13           NaN     NaN         NaN               NaN  \n",
      "\n",
      "[14 rows x 22 columns]\n",
      "Mock Background data\n",
      "   counterpart_id  K  group_id\n",
      "0               1  1       1.0\n",
      "1               2  8       1.0\n",
      "2               3  4       1.0\n",
      "3               4  5       2.0\n",
      "4               5  3       2.0\n",
      "5               6  7       3.0\n",
      "6               7  8       3.0\n",
      "7               8  5       3.0\n",
      "8               9  2       NaN\n",
      "9              10  3       NaN\n"
     ]
    }
   ],
   "source": [
    "# See our test data\n",
    "file_path = 'test_data.csv'\n",
    "data = read_csv(file_path)\n",
    "print('Mock Herschel Data')\n",
    "print(data)\n",
    "\n",
    "file_path = 'test_back.csv'\n",
    "back = read_csv(file_path)\n",
    "print('Mock Background data')\n",
    "print(back)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Function Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# =========================================================================================================\n",
    "# stellar_locus()\n",
    "# =========================================================================================================\n",
    "\n",
    "@pytest.mark.parametrize(\"x, offset, expected\",\n",
    "                         [[0, 0, 0.2228],\n",
    "                          [2, 0, 0.76],\n",
    "                          [1000, 0, 0.7768]])\n",
    "\n",
    "\n",
    "def test_stellar_locus(x, offset, expected):\n",
    "    result = utils.stellar_locus(x, offset)\n",
    "    assert expected == result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Star-Galaxy Classifier\n",
    "\n",
    "Recall that our method is:\n",
    "\n",
    "    0 - Star based on stellar probability > 0.95\n",
    "    1 - Galaxy based on J-K/g-i colour-colour plot\n",
    "    2 - Star based on J-K/g-i colour-colour plot\n",
    "    3 - Galaxy based on J-K > something\n",
    "    4 - Star based on J-K < something\n",
    "    5 - Star based on stellar probability > 0.7\n",
    "    6 - Galaxy based on all other"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    J     K    g     i  pstar  SG_flag\n",
      "0   0   0.0  0.0   0.0   0.98        0\n",
      "1   4   2.0  4.0   2.0   0.50        1\n",
      "2   4   3.5  4.0   2.0   0.50        2\n",
      "3   4   3.0  0.0  10.0   0.50        3\n",
      "4   4   3.9  0.0  10.0   0.50        4\n",
      "5   0  10.0  0.0  10.0   0.75        5\n",
      "6   0  10.0  0.0  10.0   0.50        6\n",
      "7   0   0.0  NaN   NaN   0.98        0\n",
      "8   4   2.0  4.0   2.0   0.50        1\n",
      "9   4   3.5  4.0   2.0   0.50        2\n",
      "10  4   3.0  NaN   NaN   0.50        3\n",
      "11  4   3.9  NaN   NaN   0.50        4\n",
      "12  0  10.0  NaN   NaN   0.75        5\n",
      "13  0  10.0  NaN   NaN   0.50        6\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================================\n",
    "# classification()\n",
    "# =========================================================================================================\n",
    "\n",
    "print(data[['J', 'K', 'g', 'i', 'pstar', 'SG_flag']])\n",
    "\n",
    "def test_classification(test_data):\n",
    "    df = test_data\n",
    "    expected = df['SG_flag']\n",
    "    result = utils.classification(test_data, 'counterpart_id', 'J', 'K', 'g', 'i', 'pstar')\n",
    "    assert all(expected == result)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Blanks\n",
    "\n",
    "We test the blanks function at r = 0, 9 and 15 for the minimum, maximum and a mid-value. For r = 0 we should expect all\n",
    "the groups to appear blank which equals 8. At the maximum radius, r = 15, only the no counterpart IDs will be blanks,\n",
    "which equals 2, and for the mid-value only no counterpart sources and those where all counterparts have a larger\n",
    "distance will be viewed as blanks, which is 4."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    group_id  distance\n",
      "0        1.0         4\n",
      "1        1.0         8\n",
      "2        1.0        12\n",
      "3        2.0         5\n",
      "4        2.0         3\n",
      "5        3.0         2\n",
      "6        3.0        10\n",
      "7        3.0         6\n",
      "8        4.0        13\n",
      "9        4.0        14\n",
      "10       NaN        10\n",
      "11       NaN         1\n",
      "12       NaN         0\n",
      "13       NaN         0\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================================\n",
    "# blanks()\n",
    "# =========================================================================================================\n",
    "\n",
    "print(data[['group_id', 'distance']])\n",
    "\n",
    "@pytest.mark.parametrize(\"r, expected\",\n",
    "                         [[0, 8],\n",
    "                          [9, 4],\n",
    "                          [15, 2]])\n",
    "\n",
    "def test_blanks(test_data, r, expected):\n",
    "    df = test_data\n",
    "    result = utils.blanks(df, r, 'group_id', 'distance')\n",
    "    assert expected == result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### N"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# =========================================================================================================\n",
    "# N()\n",
    "# =========================================================================================================\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### q/n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# =========================================================================================================\n",
    "# q_div_n()\n",
    "# ========================================================================================================="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Likelihood"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# =========================================================================================================\n",
    "# likelihood()\n",
    "# ========================================================================================================="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reliability\n",
    "\n",
    "**** Explain what is going on ****"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    counterpart_id  group_id  likelihood\n",
      "0                1       1.0           1\n",
      "1                2       1.0           5\n",
      "2                3       1.0          10\n",
      "3                4       2.0           2\n",
      "4                5       2.0           4\n",
      "5                6       3.0           2\n",
      "6                7       3.0           4\n",
      "7                8       3.0           6\n",
      "8                9       4.0           4\n",
      "9               10       4.0           8\n",
      "10              11       NaN           1\n",
      "11              12       NaN           5\n",
      "12              13       NaN           0\n",
      "13              14       NaN           0\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================================\n",
    "# reliability()\n",
    "# =========================================================================================================\n",
    "\n",
    "print(data[[\"counterpart_id\", \"group_id\", \"likelihood\"]])\n",
    "\n",
    "@pytest.mark.parametrize(\"q0, expected\",\n",
    "                         [[0.5, pd.Series([1/16.5, 5/16.5, 10/16.5, 2/6.5, 4/6.5, 2/12.5, 4/12.5, 6/12.5, 4/12.5, 8/12.5, 1/2, 5/6, 0, 0])],\n",
    "                          [1, pd.Series([1/16, 5/16, 10/16, 2/6, 4/6, 2/12, 4/12, 6/12, 4/12, 8/12, 1/2, 5/6, 0, 0])]])\n",
    "def test_reliability(test_data, q0, expected):\n",
    "    df = test_data\n",
    "    result = utils.reliability(df, 'counterpart_id', 'group_id', 'likelihood', q0)\n",
    "    assert all(expected == result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### N False\n",
    "\n",
    "**** Explain what is going on ****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    reliability\n",
      "0          0.05\n",
      "1          0.15\n",
      "2          0.80\n",
      "3          0.40\n",
      "4          0.60\n",
      "5          0.10\n",
      "6          0.20\n",
      "7          0.70\n",
      "8          0.40\n",
      "9          0.60\n",
      "10         0.20\n",
      "11         0.50\n",
      "12         0.00\n",
      "13         0.00\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================================\n",
    "# N_false()\n",
    "# =========================================================================================================\n",
    "\n",
    "print(data[[\"reliability\"]])\n",
    "\n",
    "@pytest.mark.parametrize(\"r_thresh, expected\",\n",
    "                         [[0, 9.3],\n",
    "                          [0.5, 1.8],\n",
    "                          [1, 0]])\n",
    "def test_N_false(test_data, r_thresh, expected):\n",
    "    df = test_data\n",
    "    result, _ = utils.N_false(df, 'reliability', r_thresh)\n",
    "    assert expected == result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Completeness\n",
    "\n",
    "**** Explain what is going on ****"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    reliability  f250  e250\n",
      "0          0.05    10     2\n",
      "1          0.15    10     5\n",
      "2          0.80    10     2\n",
      "3          0.40    10     5\n",
      "4          0.60    10     2\n",
      "5          0.10    10     5\n",
      "6          0.20    10     2\n",
      "7          0.70    10     5\n",
      "8          0.40    10     2\n",
      "9          0.60    10     5\n",
      "10         0.20    10     2\n",
      "11         0.50    10     5\n",
      "12         0.00    10     2\n",
      "13         0.00    10     5\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================================\n",
    "# completeness()\n",
    "# =========================================================================================================\n",
    "\n",
    "print(data[['reliability', 'f250', 'e250']])\n",
    "\n",
    "@pytest.mark.parametrize(\"r_thresh, expected\",\n",
    "                         [[0, 2],\n",
    "                          [0.5, 5/7],\n",
    "                          [1, 0]])\n",
    "def test_completeness(test_data, r_thresh, expected):\n",
    "    df = test_data\n",
    "    result = utils.completeness(df, 'reliability', 'f250', 'e250', q0=1, r_thresh=r_thresh)\n",
    "    assert expected == result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleanness\n",
    "\n",
    "**** Explain what is going on ****"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    reliability\n",
      "0          0.05\n",
      "1          0.15\n",
      "2          0.80\n",
      "3          0.40\n",
      "4          0.60\n",
      "5          0.10\n",
      "6          0.20\n",
      "7          0.70\n",
      "8          0.40\n",
      "9          0.60\n",
      "10         0.20\n",
      "11         0.50\n",
      "12         0.00\n",
      "13         0.00\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================================\n",
    "# cleanness()\n",
    "# =========================================================================================================\n",
    "\n",
    "print(data[['reliability']])\n",
    "\n",
    "@pytest.mark.parametrize(\"r_thresh, expected\",\n",
    "                         [[0, 9.3/2],\n",
    "                          [0.5, 1.8/5/7]])\n",
    "def test_cleanness(test_data, r_thresh, expected):\n",
    "    df = test_data\n",
    "    result = utils.cleanness(df, 'reliability', r_thresh=r_thresh)\n",
    "    assert expected == result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multiplicity Reliablity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# =========================================================================================================\n",
    "# multiplicity_reliability()\n",
    "# =========================================================================================================\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================= test session starts =======================================\n",
      "platform win32 -- Python 3.9.5, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- c:\\users\\bradl\\desktop\\venv\\scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\bradl\\Desktop\\HerschelATLASDR3_2\\testing\n",
      "collecting ... collected 17 items\n",
      "\n",
      "tmpccoc3i8n.py::test_cleanness[0-4.65] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\1138122948.py FAILED [  5%]\n",
      "tmpccoc3i8n.py::test_cleanness[0.5-0.05142857142857143] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\1138122948.py FAILED [ 11%]\n",
      "tmpccoc3i8n.py::test_blanks[0-8] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\1413748118.py PASSED [ 17%]\n",
      "tmpccoc3i8n.py::test_blanks[9-4] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\1413748118.py PASSED [ 23%]\n",
      "tmpccoc3i8n.py::test_blanks[15-2] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\1413748118.py PASSED [ 29%]\n",
      "tmpccoc3i8n.py::test_classification <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\2814409873.py PASSED [ 35%]\n",
      "tmpccoc3i8n.py::test_N_false[0-9.3] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\3331351245.py PASSED [ 41%]\n",
      "tmpccoc3i8n.py::test_N_false[0.5-1.8] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\3331351245.py PASSED [ 47%]\n",
      "tmpccoc3i8n.py::test_N_false[1-0] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\3331351245.py PASSED [ 52%]\n",
      "tmpccoc3i8n.py::test_completeness[0-2] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\3766676968.py PASSED [ 58%]\n",
      "tmpccoc3i8n.py::test_completeness[0.5-0.7142857142857143] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\3766676968.py PASSED [ 64%]\n",
      "tmpccoc3i8n.py::test_completeness[1-0] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\3766676968.py PASSED [ 70%]\n",
      "tmpccoc3i8n.py::test_stellar_locus[0-0-0.2228] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\4012963471.py PASSED [ 76%]\n",
      "tmpccoc3i8n.py::test_stellar_locus[2-0-0.76] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\4012963471.py PASSED [ 82%]\n",
      "tmpccoc3i8n.py::test_stellar_locus[1000-0-0.7768] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\4012963471.py PASSED [ 88%]\n",
      "tmpccoc3i8n.py::test_reliability[0.5-expected0] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\4088199793.py PASSED [ 94%]\n",
      "tmpccoc3i8n.py::test_reliability[1-expected1] <- ..\\..\\..\\AppData\\Local\\Temp\\ipykernel_12680\\4088199793.py PASSED [100%]\n",
      "\n",
      "============================================ FAILURES =============================================\n",
      "_____________________________________ test_cleanness[0-4.65] ______________________________________\n",
      "\n",
      "test_data =     counterpart_id  J     K    g     i  pstar  SG_flag  group_id  distance  \\\n",
      "0                1  0   0.0  0.0   0.0  ...   NaN         NaN               NaN  \n",
      "13           NaN     NaN         NaN               NaN  \n",
      "\n",
      "[14 rows x 22 columns]\n",
      "r_thresh = 0, expected = 4.65\n",
      "\n",
      "    @pytest.mark.parametrize(\"r_thresh, expected\",\n",
      "                             [[0, 9.3/2],\n",
      "                              [0.5, 1.8/5/7]])\n",
      "    def test_cleanness(test_data, r_thresh, expected):\n",
      "        df = test_data\n",
      "        result = utils.cleanness(df, 'reliability', r_thresh=r_thresh)\n",
      ">       assert expected == result\n",
      "E       AssertionError\n",
      "\n",
      "C:\\Users\\bradl\\AppData\\Local\\Temp/ipykernel_12680/1138122948.py:13: AssertionError\n",
      "_____________________________ test_cleanness[0.5-0.05142857142857143] _____________________________\n",
      "\n",
      "test_data =     counterpart_id  J     K    g     i  pstar  SG_flag  group_id  distance  \\\n",
      "0                1  0   0.0  0.0   0.0  ...   NaN         NaN               NaN  \n",
      "13           NaN     NaN         NaN               NaN  \n",
      "\n",
      "[14 rows x 22 columns]\n",
      "r_thresh = 0.5, expected = 0.05142857142857143\n",
      "\n",
      "    @pytest.mark.parametrize(\"r_thresh, expected\",\n",
      "                             [[0, 9.3/2],\n",
      "                              [0.5, 1.8/5/7]])\n",
      "    def test_cleanness(test_data, r_thresh, expected):\n",
      "        df = test_data\n",
      "        result = utils.cleanness(df, 'reliability', r_thresh=r_thresh)\n",
      ">       assert expected == result\n",
      "E       AssertionError\n",
      "\n",
      "C:\\Users\\bradl\\AppData\\Local\\Temp/ipykernel_12680/1138122948.py:13: AssertionError\n",
      "===================================== short test summary info =====================================\n",
      "FAILED tmpccoc3i8n.py::test_cleanness[0-4.65] - AssertionError\n",
      "FAILED tmpccoc3i8n.py::test_cleanness[0.5-0.05142857142857143] - AssertionError\n",
      "================================== 2 failed, 15 passed in 0.13s ===================================\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================================\n",
    "# Test\n",
    "# =========================================================================================================\n",
    "\n",
    "ipytest.run('-vv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}